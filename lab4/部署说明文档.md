## CEPH单机版部署

#### 环境说明

1台VMware虚拟机(ubuntu)

#### 安装CEPH部署工具（Ubuntu）

1. 添加release key

   ```shell
   wget -q -O- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add -
   ```

2. 添加Ceph软件包源，用Ceph稳定版（如 `cuttlefish` 、 `dumpling` 、 `emperor` 、 `firefly` 等等）替换掉 `{ceph-stable-release}`. 如：

   ```shell
   echo deb http://download.ceph.com/debian-{ceph-stable-release}/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list
   ```

3. 更新你的仓库，并安装 `ceph-deploy` :

   ```shell
   sudo apt-get update && sudo apt-get install ceph-deploy
   ```

#### 部署CEPH软件

```shell
mkdir myceph
cd myceph
ceph-deploy new {hostname}
```

若提示

```shell
UnableToResolveError: Unable to resolve host: {hostname}
```

则修改 /etc/hosts，添加相应的IP地址和hostname，然后重新deploy。

#### 设置集群副本数量

把如下内容加入到 ceph.conf 里面。

```shell
[global]
osd pool default size = 1
osd pool default  min size = 1 
```

#### 安装(luminous 版)

```shell
ceph-deploy install --release luminous {hostname} 
```

#### 初始化 mon

```
ceph-deploy mon create-initial
ceph-deploy admin {hostname}
```

#### 部署ceph mgr

```shell
sudo chmod +r /etc/ceph/ceph.client.admin.keyring
ceph-deploy mgr create {hostname}
```

#### 部署osd

安装lvm2

```shell
sudo apt install lvm2
```

若无sdb，则在虚拟机里添加一个硬盘，然后

```shell
sudo su
cd
pvcreate /dev/sdb
```

然后在myceph目录下

```
ceph-deploy osd create --data /dev/sdb {hostname}
```

部署完毕，可以通过以下命令查看系统状态

```shell
ceph -s
```

![ceph_s](https://github.com/OSH-2021/x-seLVM/blob/main/pictures/ceph_s_1.png?raw=true)



## 树莓派单机部署ceph

### Step1:树莓派安装操作系统

1. 在[树莓派官网](https://www.raspberrypi.org/downloads/)下载操作系统镜像文件`RASPBIAN`
2. 在[树莓派官网](https://www.raspberrypi.org/downloads/)下载镜像安装软件`Raspberry Pi Imager`
3. 利用`Raspberry Pi Imager`将我们下载的镜像文件安装到SD卡中
4. 启动树莓派并打开`ssh`功能
   - 如果有显示屏输出和键盘与鼠标输入
     1. 打开命令行
     2. 输入`sudo raspi-config`
     3. 选择`5 Interfacing Options`选项 
     4. 选择`SSH`选项
     5. 选择是并回车
     6. 选择`Finish`保存设置
   - 没有显示屏或者相应的输入控制设备
     1. 用读卡器将SD卡连接至电脑
     2. 在boot下新建`SSH`文件

### Step2:SSH远程连接树莓派

1. 在树梅派命令行输入`sudo ifconfig`查询树梅派的ip地址**pi_address**
2. 在命令行输入`ssh pi@pi_address`进行远程ssh连接(可能需要提前设置好树莓派的密码)

### Step3:安装必要工具

1. 安装`ceph-deploy`

   `sudo apt-get install ceph-deploy`

2. 安装`lvm2`

   `sudo apt-get install lvm2`

### Step4:创建工作区

1. 先随便创建一个文件夹

   ```shell
   mkdir test
   cd test
   ```

2. 初始化`ceph-deploy`

   - 先用`hostname`命令获取树莓派的主机名(你也可以用`hostnamectl set-hostname NAME `修改树莓派的主机名，方便记忆和配置)

   - 命令行输入`ceph-deploy new HOST-NAME` 其中HOST-NAME是我们查询到的树莓派主机名

   - 命令行输入`vim /etc/hosts`，并将文件中的`127.0.0.1   HOST-NAME`这一行修改为`Pi_address   HOST-NAME`,其中`Pi_address` 和 `HOST-NAME`的意义均在上文提及且保持一致。

   - 修改`ceph.conf`

     `vim ceph.conf`

     在文件最末尾添加输入

     ```
     osd pool default size = 1
     osd pool default min size = 1
     ```

     保存并退出

   - 获取`Ceph Version Name`

     命令行输入`ceph --version`获取ceph的版本**ceph-version-name**(即版本号)

   - 命令行输入并执行以下命令初始化`ceph`，并部署`admin`、`monitor`节点

     ```shell
     ceph-deploy install --release {Ceph Version Name} {Host Name}
     ceph-deploy mon create-initial
     ceph-deploy admin {Host Name}
     sudo chmod +r /etc/ceph/ceph.client.admin.keyring
     ceph-deploy mgr create {Host Name}
     ```

### Step5:挂载储存区域

建议挂载U盘(

1. 给树莓派插一个U盘(不解释)

2. 使用命令

   ```shell
   sudo fdisk -l
   ```

   查看U盘的挂载情况，如果能够看到`/dev/sda`的挂载和具体`/dev/sdax`之类的显示，则说明挂载正常。

   否则需要手动挂载或创建分区(可参考[手动创建分区](https://blog.csdn.net/ANXIN997483092/article/details/82907016?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162626939016780274193735%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=162626939016780274193735&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-1-82907016.pc_search_result_control_group&utm_term=Device+%2Fdev%2Fsda5+not+found&spm=1018.2226.3001.4187))

3. 部署OSD节点

   ```shell
   pvcreate /dev/sda
   vgcreate  ceph-pool /dev/sda
   lvcreate -n osd0.wal -L 1G ceph-pool
   lvcreate -n osd0.db -L 1G ceph-pool
   lvcreate -n osd0 -l 100%FREE ceph-pool
   
   ceph-deploy osd create \
       --data ceph-pool/osd0 \
       --block-db ceph-pool/osd0.db \
       --block-wal ceph-pool/osd0.wal \
       --bluestore Host-Name
   ```

4. 完成部署啦！

5. 查看系统状态

   使用命令

   ```shell
   ceph -s
   ```

   或者使用

   ```shell
   ceph mgr module enable dashboard
   ceph mgr services
   ```

   获得输出端口**port**，用浏览器打开网址`pi_address:port`,即可图形化查看系统状态

6. 可能有的问题

   - OSD节点未成功上线

     使用指令

     ```shell
     systemctl | grep ceph
     ```

     查看ceph相关的进程服务

     1. 如果存在`ceph-osd@1.service`进程且状态为`active`

        则使用命令`systemctl restart ceph-osd@1.service`重启该服务即可

     2. 若根本不存在`ceph-osd@1.service`进程

        则输入如下指令

        ```shell
        ceph osd out osd.1
        systemctl stop ceph-osd@1.service
        ceph-osd -i 1    
        ```

        若得到提示

        ```
        starting osd.1 at - osd_data /var/lib/ceph/osd/ceph-1 /home/nvme/ceph/ceph-1/journal
        ```

        则意味着执行成功

     之后再用5中的指令查看系统状态即可

     

## CEPH分布式部署

### 一、环境说明

3台VMware虚拟机：Ubuntu18.04(python3版本为3.6.9，实测python版本3.8.10不支持platform.linux_distribution属性，也需要python2环境）

node1: admin node, monitor, mgr

node2: osd0

node3: osd1

### 二、准备工作

#### 在所有节点安装SSH服务器

```shell
sudo apt-get insatll openssh-server
```

####  修改hostname为node1, node2, node3

```shell
sudo vim /etc/hostname
```

#### 确保各节点主机名解析为网络IP地址而非回环接口地址（127.0.0.1）

```shell
ip address      #查看网络IP地址
sudo vim /etc/hosts		#添加一行: {hostname}  {IP address}
```

#### 配置管理主机node1, 使之可以通过SSH无密码访问各节点

```shell
ssh-keygen
ssh-copy-id node2
ssh-copy-id node3
```

####  管理主机上安装ceph-deploy

```shell
shudo apt-get install ceph-deploy
ceph-deploy --version	#查看ceph-deploy版本 e.g. 2.0.1
```

#### 在所有节点安装NTP并使用同一个NTP服务器, 避免时钟偏移

```shell
sudo apt-get install ntp
ntpstat		#查看ntp连接的服务器
```

#### 确保各节点的用户都有sudo权限

```shell
echo "{username} ALL = (root) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/{username}
sudo chmod 0440 /etc/sudoers.d/{username}
```

### 三、CEPH部署

#### 在管理节点新建工作目录，后续操作在工作目录下完成

```shell
mkdir my-cluster
cd my-cluster
```

#### 创建monitor节点，生成一个ceph 配置文件、一个monitor密钥环和一个日志文件

```shell
ceph-deploy new node1		#node1作为monitor节点
```

#### 把ceph .conf里的默认副本数从3改成2, 把下面这行加入global段：

```shell
osd pool default size = 2
```

#### 安装ceph, --release {stable ceph version}设置希望安装的ceph版本

```shell
echo deb http://download.ceph.com/debian-{ceph-stable-release}/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list		#添加ceph软件包源
ceph-deploy install --release nautilus node1 node2 node3
```

#### 初始化monitor节点，生成monitor节点检测集群所需要的密钥文件

```shell
ceph-deploy mon create-initial
sudo chmod +r /etc/ceph/ceph.client.admin.keyring	#确保有读权限
ceph-deploy admin node1 node2 node3		#将生成的ceph.client.admin.keyring和配置文件push到各节点
```

#### 有monitor节点之后就可以查看集群状态

```shell
ceph -s
ceph health
```

#### 部署mgr节点

```shell
ceph-deploy mgr create node1
```

#### 部署osd节点

```shell
ceph-deploy osd create node2 --data /dev/sdb	#如果没有硬盘，需要新建
ceph-deploy osd create node3 --data /dev/sdb
```

![ceph -s查看部署完成后的集群状态](https://github.com/OSH-2021/x-seLVM/blob/main/pictures/ceph分布式部署.png)







