# 调研报告

## **目录**

[TOC]

## **项目成员**

| 成员姓名 | 学号       | 邮箱                        |
| -------- | ---------- | --------------------------- |
| 张一方   | PB19051001 | zyf001028@mail.ustc.edu.cn  |
| 陶思成   | PB19050991 | tsc2001@mail.ustc.edu.cn    |
| 林晨阳   | PB19111758 | lcy2333@mail.ustc.edu.cn    |
| 吴晨源   | PB19071467 | wuchenyuan@mail.ustc.edu.cn |
| 刘佳如*  | PB19081601 | liujiaru@mail.ustc.edu.cn   |

## **项目简介**

本项目旨在对Inferno进行微内核式改造、优化和功能扩展，希望实现一个类似Inferno、适用于多种平台、采用分布式数据管理、安全、高性能的微内核，能够在各种应用场景尤其是分布式场景中展现良好的性能，成为适应多核、多平台硬件现状的通用操作系统内核。参考项目有seL4、Inferno、Java、Android、鸿蒙、Linux等。

## **项目背景**

### **inferno**

#### 背景

------------

##### 分布式操作系统

分布式操作系统（Distributed operating system）是运行于一系列在物理上独立，但又相互连成网络，进行通信的计算节点上的系统软件[^5]。每个单独的计算节点都拥有全局集合操作系统的特定部分软件子集，而每个软件子集都是以下两个不同的服务提供者的组合: 第一个是最小内核或者称为微内核，由它直接控制该计算节点的硬件。第二个是更高级别的系统管理组件集合,它能够协调计算节点内部的独立工作与之间的协作活动。对硬件而言，各个计算机都是自洽的；而对软件来讲，用户将整个系统看作是一台计算机。

通过分布式操作系统，用户能够方便地访问远程资源，并以一种受控的方式与其他用户共享这些资源，进而更高效地利用底层资源[^4]。此外分布式的结构也保证了计算节点的可靠性、安全性与可扩展性。

<img src="https://upload.wikimedia.org/wikipedia/commons/d/d0/OS-structure2.svg" alt="OS-structure2" style="zoom: 50%;" />

​									[Structure of monolithic kernel, microkernel and hybrid kernel-based operating systems]

一个优秀的分布式操作系统需具有如下特性：

- 高透明性
- 高IPC
- 高效的进程与资源管理

###### 透明性[^4]

如果一个分布式系统能够在用户和应用程序前呈现为单个计算机系统，这样的分布式系统就称为透明的。透明性代表了将隐藏系统内部进程和资源实际上是分布的这样一个事实的能力。透明性的考虑直接影响分布式操作系统设计各个方面的决策。透明度可能对其他设计考虑因素施加某些要求和限制。故对透明性进行仔细考量是必要而且具有极大意义的。

透明性在系统的以下几个方面有体现：

| 透明性 | 说明                                         |
| ------ | -------------------------------------------- |
| 访问   | 隐藏数据表示形式的不同以及资源访问方式的不同 |
| 位置   | 隐藏资源所在位置                             |
| 迁移   | 隐藏资源是否移动到另一个位置                 |
| 重定位 | 隐藏资源是否在使用过程中移动到另一个位置     |
| 复制   | 隐藏是否对资源进行复制                       |
| 并发   | 隐藏资源是否由若干相互竞争的用户共享         |
| 故障   | 隐藏资源的故障和恢复                         |



###### IPC进程间通信

IPC进程间通信（Inter-Process Communication）是在节点内以及分布式OS中的节点之间的线程和/或进程之间进行常规通信，进程交互以及数据流的实现。节点间和节点间的通信需求驱动了低级IPC设计，这是实现支持透明性的通信功能的典型方法。IPC的性能直接决定了节点的通信性能，进而直接决定了整体的计算性能。

IPC的实现具有多种不同的方法，一些比较常用的IPC实现如下：[^6]

|      实现方法      |                             简介                             | 应用于何种操作系统（或环境）  |
| :----------------: | :----------------------------------------------------------: | :---------------------------: |
| Memory mapped file | 映射到RAM的文件，可以通过直接更改内存地址而不是输出到流来修改。这具有与标准文件相同的优点 |    所有POSIX系统，Windows     |
|      消息队列      |         消息队列保存在内核中，是一个由消息组成的链表         |        大多数操作系统         |
|     **Socket**     | 套接字(Socket)是由Berkeley在BSD系统中引入的一种基于连接的IPC，是对网络接口(硬件)和网络协议(软件)的抽象。它既解决了无名管道只能在相关进程间单向通信的问题，又解决了网络上不同主机之间无法通信的问题。 | 所有POSIX操作系统和Windows 10 |
|      共享内存      | 共享内存允许两个或多个进程共享一定的存储区，因为不需要拷贝数据，所以这是最快的一种IPC |    所有POSIX系统，Windows     |

-----

#### Inferno简介

Inferno是贝尔实验室开发的可以创造并支持分布式服务的操作系统。Inferno应用程序可以移植到大多数混合的硬件、网络、环境上。它也定义了一套名为Dis的虚拟机，这个虚拟机可以在任何实体机器上运行，使用Limbo这种类型安全的语言来编译成比特码。Inferno也提供了具备相同接口的虚拟操作系统来让用户可以在硬件上原生地运行Inferno或以应用程序的方式托管在其他系统中运行。

不同于其他分布式操作系统的IPC，Inferno使用一种名为Styx的通信协议被用来让系统内可以 采用一致的方式，让应用程序只要使用标准的文件操作，如开启、读取、写入，以及关闭，就可以访问近端与远程的资源。

作为分布式操作系统，Inferno相比传统的操作系统技术具有以下优点[^7]：

- **不同处理器的可移植性 **  目前可以在ARM、MIPS、PA-RISC、PowerPC、SPARC，以及x86等架构上运作，也可以移植到其他的架构上。

- **不同环境的可移植性**  它可以以独立的操作系统运作在小型终端上，或是以用户应用软件的形式存在于其他他操作系统上，如Windows NT、Windows 95、UNIX、Solaris、FreeBSD、GNU/Linux、AIX、HP-UX。Inferno应用程序在这些环境中都有相同的接口。
- **高效方便的资源调用** 在用户终端以及服务器的部分都具有相同的环境，而且彼此间可以导入对方的资源（例如附加的输入/输出设备或是网络）。应用程序可以在运行系统中的通信机制辅助之下，轻松的（甚至是动态的）分散到客户端或服务端。
- **最低硬件需求** 它在机器上所运行的实用应用程序只需要1MB的存储器，也不需要存储器映射的硬件支持
- **动态适应性（Dynamic adaptability）**:应用程序可以根据硬件或其他可用资源来加载不同的程序模块来运行特定的功能。例如像视频播放器可以使用许多不同解码模块中的任何一个来进行视频的解码。

#### Inferno中的重要设计理念

- **层次结构式文件系统**

  > Unix之前的操作系统都各自不同的API来访问不同类型的设备，Unix尝试透过磁盘引索节点(disk inodes)来消除这些API之间的差距，从而向用户隐藏底层实现的细节。但是许多关键的概念（如控制行程的状态）并没有一致地对应到文件系统上。
  >
  > 
  >
  > Inferno并不采用这样的实现，而是回归**以文件系统为中心(file system-centric)**[^8]的系统观点。无论是网络或者用户界面、甚至是视窗本身，所有可用资源对于Inferno的每个程序来说，都是层次结构式文件系统的一部分，而非特定的接口

- **独立配置的名字空间与合并目录**

  >Inferno的一个创新点则是用户可以对相同的“真实世界”对象各自分别取不同的名称。每个用户都可以借由在他们的名字空间中收集各式各样不同的对象来创造属于他们自己的个人化环境。UNIX也有类似的观念，用户可以复制其他用户来获取权限。但是Inferno则把这种作法扩展到所有的对象，用户可以轻易地产生自身的“复制品”，加以修改，就算移除这些复制品也不会影响他们创造过的资源。
  >
  >
  >
  >Inferno的另一个创新点是采用合并目录的方式，从不同媒体或网络资源合并的目录以透明（transparently）的方式绑定[^9]。举例来说，可以把别台电脑的`/bin`（应用程序）目录跟本机端绑定，接下来这个目录就会同时有本地端以及远程的应用程序在里面，用户可以无障碍的访问近端或是远程的程序。使用相同系统的情况下，Inferno所控制的外部设备与资源可以绑定到`/dev`目录下，这可以让设备不需要任何额外的程序，就可以透过网络进行访问、修改和分享。例如：
  >
  >> - **`/proc`** 目录
  >
  >> 列出所有运行中**行程**。
  >
  >> 不同于其他核心资源的是，行程以`/proc`目录下的命名对象（内含信息与控制文件的子目录）的形式表现，并给予用户一组动态的输入/输出通道来对行程发送指令及读取资料。用户无须使用受限的系统调用来与编译过的程序核心交互，相反的，它可以使用如`ls`以及`cat`等指令来搜索、查询、以及操作行程。
  >
  >> 用户也可以从其他的机器上将`/proc`目录（以及任何其他特定的文件系统）挂载到自己的名字空间中，就如同这些程序是在本机端一般地与它们交互。结果就是利用个别的机器架构出一套分布式运算环境，这些机器可能是用户桌上的终端、存储长期资料的文件服务器、提供较快CPU及运算能力、用户审核、网关等服务之其他服务器，全部都采用为大多数电脑用户所熟悉的既有的层次结构式目录/命名系统。用户可以借由终端来收集文件服务器、服务器上所运行的应用程序、网络上的打印机等设备，绑定进自己的名字空间进而"建构"出一套系统。
  >
  >> - **`/net`** 目录
  >
  >> Inferno并没有使用任何系统调用来处理众多的通信协议或设备驱动程序的接口，在`/net`目录下包含了所有TCP/IP的API，并可借由使用脚本语言或[命令行接口的工具来撰写可以控制文件对连线进行写入或读取的程序。
  >
  >> 底下的子目录如`/net/tcp`和`/net/udp`等目录用来对应各种协议的接口。用户可以借由挂载一台具有公开（public）IP地址的外部机器的`/net`目录，来让使用Styx网络协议的内部网私有（private）IP地址，能透过该外部机器进行连线的方式，进而达到实做NAT的效果。又或者用户可以借由挂载远程网关的`/net`目录，在公开网络上使用加密（secured）的9P协议达成实做VPN的效果。

- **标准通信协议Styx**

  >Inferno设计上想达成运算系统核心功能间彼此沟通的观念。所有系统资源都被当成文件般地命名及访问，并提供可根据在特定机器上各个程序设置的多种分布式系统视图（view）。这种让服务器以类似传统文件的方式，把任何信息都呈现给用户及应用程序的实现方式，增进了应用程序设计上的一般化与模块化的能力。
  >
  >
  >
  >Inferno支持网络通透性的关键在于采用一种新的底层网络协议Styx。Styx协议实现了链接到命名网络对象并以类文件（file-like）系统呈现的方式。借由快速的比特导向（而非[区块导向，分布式文件系统可以把任何对象可视化的呈现，而非透过远程机器上的一个NFS(服务器再加以呈现。这个协议可以用来跟行程、程序、资料、以及包含用户界面及网络以及彼此之间进行通信
  >
  >
  >
  >**Syx的实现**[^8]
  >
  >​	Inferno在客户端及服务端间提交如下的消息,这些消息对应到虚拟文件系统层的进入点，所有的服务器都必须实现这些消息:
  >
  >- version: 交涉协议的版本
  >- error: 回报错误
  >- flush : 终止消息
  >- auth, attach : 开启连线
  >- walk : 走访目录层次结构
  >- create, open : 准备一个用来写入/读取既有或新增文件的fid
  >- read, write : 发送资料给文件或从文件接收资料
  >- clunk : 抛弃fid
  >- remove: 从服务器移除文件
  >- stat, wstat : 查询或变更文件属性
  >
  >Styx客户端将请求作为“ T消息”发送到服务器并收到匹配的“ R-messages”的回复。T消息在这里用Tmsg类型的值表示，并且消       息的类型为Rmsg。每条消息都有一个标签值，pick adt的替代项代表T消息的可能操作类型。通过这种方式实现服务段与客户端之间的通信。

### **虚拟机**

#### 虚拟机的定义

虚拟机（*Virtual Machine*），在计算机科学中的体系结构里，是指一种特殊的软件，他可以在计算机平台和终端用户之间建立一种环境，而终端用户则是基于这个软体所建立的环境来操作软件。在计算机科学中，虚拟机是指可以像真实机器一样运行程序的计算机的软件实现

#### 虚拟机的分类

　　①、系统虚拟机：是完全对物理计算机的仿真，可以说和一台真实的PC操作系统没什么区别。比如常用的 Vmare 以及 Visual Box 软件，通过这些软件能够模拟出具有完整硬件系统功能的、运行在一个完全隔离环境中的完整计算机系统。

　　②、程序虚拟机：专门为执行单个计算程序而产生，最典型的就是Java虚拟机，在Java虚拟机中执行字节码文件命令。

#### 程序虚拟机的工作原理

JVM或者Python中，JAVA或者python源码会被编译成相关字节码，然后在对应虚拟机上运行，JVM或Python会对这些字节码进行取指令，译码，执行，结果回写等操作，这些步骤和真实物理机器上的概念都很相似。相对应的二进制指令是在物理机器上运行，物理机器从内存中取指令，通过总线传输到CPU，然后译码、执行、结果存储

他应该能够模拟物理CPU对操作数的移进移出，理想状态下，它应该包含如下概念[1]：
（1）将源码编译成VM所能执行的具体字节码。
（2）字节码格式（指令格式），例如三元式，树还是前缀波兰式。
（3）函数调用相关的栈结构，函数的入口，出口，返回以及如何传参。还有为了能够顺利返回所需的相关栈帧信息如何布置。
（4）一个“指令指针”，指向下一条待执行的指令（内存中），对应物理机器的EIP。
（5）一个虚拟“CPU”-指令调度器
      1）取指：获取下一条指令（通过IP获取），指令来源于内存
      2）译码：对指令进行翻译，将要作何种操作，同时从内存中取操作数
      3）执行：指令译码后，被虚拟机执行指令(最终都会借助物理机资源)
      4）回写：执行后生成的结果回写进存储器。

#### Stack-based虚拟机

基于Stack的虚拟机有JVM、.net的CLR，这种基于Stack实现虚拟机是一种广泛的实现方法。这样做的直接好处就是：

1. 虚拟机可以无视具体的物理架构，可移植，寄存器由硬件直接提供。使用栈架构的指令集，用户程序（编译后的字节码）不会直接使用硬件中的寄存器，同时为了提高运行时的速度，可以将一些访问比较频繁的数据存放到寄存器中以获取尽量好的性能。
2. 由于操作数都是隐式地，所以指令可以做的很短，指令更加紧凑，一个字节或者两个字节即可存储。但是显而易见就是指令条数会显著增加
3. 编译器实现也比较简单，不用进行寄存器分配

缺点[1]：

1. 操作数栈和局部变量表都是存放在内存上，内存到内存的数据传输在x86的机器上都是要经过一次数据总线传输的但缺点也显而易见，就是速度慢，因为无论什么操作都要通过操作数栈这一结构。

2. 指令数目显著增加

#### Register-based 虚拟机

  基于寄存器的虚拟机，它们的操作数是存放在CPU的寄存器的。没有入栈和出栈的操作和概念。但是有很多虚拟寄存器，一般情况下这些寄存器（操作数）都是别名，需要执行引擎对这些寄存器（操作数）的解析，找出操作数的具体位置，然后取出操作数进行运算。这不像栈可以用栈指针去操作。比如如下的加法操作 **ADD R1, R2, R3** ;就一条指令搞定了

基于Register的虚拟机有Lua VM（是Lau编程语言的虚拟机）和Dalvik VM；

新的虚拟机也用栈分配活动记录，寄存器就在该活动记录中。当进入Lua程序的函数体时，函数从栈中分配一个足以容纳该函数所有寄存器的活动记录。**函数的所有局部变量都各占据一个寄存器。因此，存取局部变量是相当高效的**

其实“寄存器”的概念只是当前栈帧中一块连续的内存区域。这些数据在运算的时候，直接送入物理CPU进行计算，无需再传送到operand stack上然后再进行运算。例如"ADD R3, R2, R1"的示意图就如下所示

![register-based add](C:\Users\ASUS\Desktop\register-based add.jpg)

​	假如一个VM采用基于寄存器的架构（它接受的指令集大概就是二地址或者三地址形式的），为了高效执行，一般会希望能把源架构中的寄存器映射到实际机器上寄存器上。**但是VM里有些很重要的辅助数据会经常被访问，例如一些VM会保存源指令序列的程序计数器（program counter，PC），为了效率，这些数据也得放在实际机器的寄存器里。**如果源架构中寄存器的数量跟实际机器的一样，或者前者比后者更多，那源架构的寄存器就没办法都映射到实际机器的寄存器上；这样VM实现起来比较麻烦，与能够全部映射相比效率也会大打折扣。**像Dalvik VM的解释器实现，就是把虚拟寄存器全部映射到栈帧（内存）里的，这跟把局部变量区与操作数栈都映射到内存里的JVM解释器实现相比实际区别不太大**[2]

1. 使用寄存器式虚拟机没有基于栈的虚拟机在拷贝数据而使用的大量的出入栈（push/pop）指令。同时指令更紧凑更简洁。但是由于显示指定了操作数，所以基于寄存器的代码会比基于栈的代码要大，但是由于指令数量的减少，其实没有大多
2. 基于寄存器得虚拟机还有一个优点就是一些在基于Stack的虚拟机中无法实现的优化，比如，在代码中有一些相同的减法表达式，那么寄存器只需要计算一次，然后将结果保存，如果之后还有这种表达式需要计算就直接返回结果。这样就减少了重复计算所造成的开销。
     	

**栈式虚拟机 VS 寄存器式虚拟机**[2]

（1）**指令条数：栈式虚拟机多**
（2）**代码尺寸：栈式虚拟机小**
（3）**移植性：栈式虚拟机移植性更好**
（4）**指令优化：寄存器式虚拟机更能优化**

| 栈式 VS 寄存器式         | 对比               |
| ------------------------ | ------------------ |
| 指令条数                 | 栈式 > 寄存器式    |
| 代码尺寸                 | 栈式 < 寄存器式    |
| 移植性                   | 栈式优于寄存器式   |
| 指令优化                 | 栈式更不易优化     |
| 解释器执行速度           | 栈式解释器速度稍慢 |
| 代码生成难度             | 栈式简单           |
| 简易实现中的数据移动次数 | 栈式移动次数多     |

虽然零地址指令更紧凑，但完成操作需要更多的load/store指令，也意味着更多的指令分派（instruction dispatch）次数与内存访问次数；访问内存是执行速度的一个重要瓶颈，二地址或三地址指令虽然每条指令占的空间较多，但总体来说可以用更少的指令完成操作，指令分派与内存访问次数都较少

#### 解释器

实现程序执行的一种实现方式，与编译器相对。它直接实现程序源码的语义，输入是程序源码，输出则是执行源码得到的计算结果；编译器的输入与解释器相同，而输出是用别的语言实现了输入源码的语义的程序。通常编译器的输入语言比输出语言高级，但不一定；也有输入输出是同种语言的情况，此时编译器很可能主要用于优化代码。 

解释器最重要的开销在于指令调度(instruction dispatch)，指令调度主要操作包括从内存中取出指令，然后跳转到解释器相对应的代码段，然后执行这条指令。

1. 其中一个简易实现就是使用switch-based的方式来进行，这种方式简单易实现，另外任何语言都有相应的switch语句。switch-based的指令调度，通过一个死循环不断的从内存取出指令来执行，针对不同的指令选择不同的执行方式[3]

   ]![SBD实现方式](C:\Users\ASUS\Desktop\SBD实现方式.jpg)

   方式实现简单，代码移植性好，但是有一个缺点就是分支预测失效的概率比较高



#### Dalvik虚拟机

##### 1. 可执行文件格式与字节码

Dalvik虚拟机的可执行文件被封装成 dex 文件格式，编译器将运行时用到的类编译成 dex 文件，然后由虚拟机加载执行。dex 文件中所有类都共享常量池，使得相同的字符串、相同的数字常量等都只出现一次，减小了文件的体积；为了节省内存，dex 文件被部署到目标平台时，Dalvik 虚拟机优化了其中的代码布局，运行程序时就不需要改动 dex 文件的内容，直接将其映射到内存中用于执行，提高了运行效率。

Dalvik 虚拟机与 JVM 不同，JVM 是基于栈的架构，而Dalvik 虚拟机是基于寄存器的架构，其字节码主要是二地址/三地址混合形式。Dalvik 虚拟机将虚拟寄存器映射到实际寄存器上，**这样运行在 RISC 处理器的虚拟机更能发挥基于寄存器架构的优势**[1]

##### 2.Dalvik 虚拟机的组成

在 Dalvik 的源码目录中，vm 目录包含虚拟机实现的代码，是虚拟机的核心部分，平台相关部分分别放在 arch 和mterp 目录中。arch 目录主要完成 JNI 方法调用，用来调用一个 C/C++的 JNI 方法，各平台的实现必须遵守本地调用约 定；mterp 目录是虚拟机解释器在各平台上的具体实现。**主要的工作就是针对这 2 个目录中的代码进行修改**

Dalvik 虚拟机内部结构包括类装载器、方法区、堆、栈、寄存器和执行引擎等几个重要组成部分，其内部结构如图所示

![image-20210417165601983](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210417165601983.png)

##### 3. Dalvik解释器的实现

Dalvik 虚拟机字节码执行方式主要为解释执行，移植的关键点是实现字节码解释程序，具体实现由汇编代码完成，解释器的实现在源码树的 vm/interp 和 vm/mterp/mips目录中。字节码的解释执行流程如图 3 所示。

![image-20210417170114876](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210417170114876.png)



### **seL4** [^图片来源][^1]                                                                    ![logo](https://sel4.systems/images/logo-text-white.svg)

#### 概述[^1]

seL4是一个高安全性、高性能的操作系统微内核，是L4系列微内核中的一个，由Trustworthy Systems Group于2009年发布，支持主流的ARM、x86和RISC-V架构，现已开源并成立基金会。

seL4的突出特点在于其经过形式化验证的安全性，以及保障安全性的同时所具有的高性能，在对于安全性要求较高的军事、商业、政治领域有着众多应用场景。[^图片来源：][^3]![image-20210408212051029](C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210408212051029.png "L4系列族谱")

##### 最小化原则

seL4作为一个微内核，为所有系统服务和用户程序提供资源的访问控制、为各个系统组件提供通信，是操作系统的核心部分，具有优先权限。seL4坚持了微内核的“最小化原则”，将大量的硬件驱动和系统服务裁减掉，甚至将内核内存分配和时间片分配丢到用户空间中，以实现微内核的最小化。由此带来的好处是拥有许多的应用场景，为场景中的多种操作系统提供可靠的基础支持。[^图片来源：][^3]![image-20210408211958079](C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210408211958079.png "宏内核与微内核比较")

##### 安全性

L4系列微内核已经是全球最先进、最安全的操作系统内核，而seL4又在其中出类拔萃。seL4是世界上第一个且是迄今为止唯一一个经过安全性形式验证的操作系统。seL4的安全性表现为在它为系统中运行的应用程序之间的隔离提供了最高的保证 ，这意味着可以遏制系统某一部分的妥协，并防止损害该系统其他可能更关键的部分。[^图片来源：][^3]

![seL4Kernel](https://sel4.systems/images/trusted.svg "seL4提供的隔离")

![image-20210408212214009](C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210408212214009.png "seL4的形式化验证")



##### 性能

正如seL4官网标题下的第一条标语：“Security is no excuse for bad performance（安全性不是降低性能的借口）”，seL4在保障了首屈一指的安全性的同时也兼顾了其性能。seL4的性能较此前的系统内核不仅没有降低，反而得到了增强。一个显著的指标就是其IPC时间较之其他的OS内核减少了至少一半。

#### 内核基本服务[^2]

1. 线程抽象：支持运行软件的CPU执行；
2. 分配地址空间：为应用程序提供虚拟的内存空间，使应用程序只能访问该空间中的内存而不会破坏系统空间；
3. 管理进程间通信：允许进程间通过端点进行数据传输，协调各个进程的资源占用和释放；
4. 通知：提供类似于二进制信号量的非阻塞信号机制，让进程的数据访问更加高效；
5. 设备原语：将设备驱动程序作为非特权应用程序实现，内核通过IPC消息导出硬件设备中断；
6. 分配功能空间：分配存储内核服务的内存空间并设置特权权限。

#### 访问控制[^2]

seL4微内核提供了一个基于功能的访问控制模型。访问控制管理所有内核服务，为了执行操作，应用程序必须调用其拥有的对请求的服务具有足够访问权限的功能。

访问控制将操作系统配置为相互隔离的软件组件，通过有选择地授予特定的通信能力，在组件之间启用授权的、受控的通信，使得软件组件具有高度保证的隔离，因为只有那些由能力占有明确授权的操作才被允许。

#### 系统调用[^2]

seL4内核提供了一个用于在线程之间传递消息的服务，该机制还用于与内核提供的服务进行通信。该通信服务传递的消息具有标准的格式，每个消息包含一些数据字和一些可能的功能。

线程通过调用其功能空间中的功能来发送消息，当以这种方式调用一个端点功能时，消息将通过内核传输到另一个线程。当调用内核对象的功能时，消息将被解释为以特定于内核对象类型的方式进行的方法调用。

逻辑上，内核提供三个系统调用：发送、接收和输出。除此之外，还有一些基本的Send和Receive调用的组合和变体，如Call操作，由来自同一个对象的一个Send和一个Receive组成。除了端点和通知之外，内核对象上的方法都映射到发送或调用，具体映射到哪种方法取决于方法是否返回结果。具体的8种系统调用参见[^seL4手册：内核服务与对象]。

#### 内核对象[^2]

seL4微内核中实现了一些对象类型，这些类型的实例（也称为“对象”）可以由应用程序调用，而这些对象的接口也构成了内核本身的接口。内核服务的创建和使用是通过创建、操作和组合这些对象来实现的。具体的对象类型如下：

+ **CNodes**：存储功能，允许线程调用特定对象上的方法，每个结点都有固定数量的插槽，数量通常为2^n个。插槽数量取决于结点的创建时间，插槽可以是空的也可以包含功能。
+ **TCB**（线程控制块）：表示seL4中的一个运行线程，线程是调度、阻塞、非阻塞等的执行单元，具体执行的内容取决于应用程序与其他线程的交互。
+ **Endpoints**（端点）：负责进程之间的消息传输。通过端点进行的IPC是同步的，试图在端电上发送或接收消息的线程会阻塞，直到消息可以传递为止，这意味着只有当发送者和接收者在端点汇合时，消息传递才会发生，内核可以通过一个拷贝传递消息。端点的功能可以被限制为只发送或只接收。端点功能可以拥有授予权，这允许将功能作为消息的一部分发送。
+ **通知对象**：提供一个简单的信号机制。一个通知是1Byte大小的标志数组，每个标志的行为都像一个二进制信号量。在单个操作中向标志的子集发出信号，轮询检查所有标志，并保持阻塞直到某一标志作为标志被发出。通知功能可以是仅限信号的或仅限等待的。
+ **虚拟地址空间对象**：用于为一个或多个线程构造虚拟地址空间，这些对象很大程度上直接对应于硬件对象，因此依赖于体系结构。内核还包括用于跟踪地址空间状态的ASID池和ASID控制对象。
+ **中断对象**：中断对象给应用程序接收和确认来自硬件设备的中断的能力。最初，IRQControl有一个功能，它允许创建IRQHandler功能。IRQHandler功能允许管理与特定设备相关联的特定中断源。它被委托给一个设备驱动程序来访问中断源。IRQHandler对象允许线程等待并确认单个中断。
+ **非类型化内存**：无类型内存是sel4内核中内存分配的基础。非类型化内存功能只有一个方法：创建新的内核对象。如果方法成功，调用线程将获得对新创建对象的功能的访问权。此外，非类型化内存对象可以划分为一组较小的非类型化内存对象，允许委托部分(或全部)系统内存。

#### 内核内存分配[^2]

seL4微内核不为内核对象动态分配内存，必须通过非类型化内存能力，从应用程序控制的内存区域显式创建对象。应用程序必须有明确的内存权限（通过非类型化内存能力）才能创建新对象，并且所有对象一旦创建就会消耗固定数量的内存。这些机制可用于精确控制应用程序可用的物理内存的具体数量，包括能够强制隔离应用程序或设备之间的物理内存访问。

除了由硬件规定的资源之外，内核中没有对任何资源的限制，因此可以避免许多由于资源耗尽而导致的拒绝服务。

在引导时，seL4预先分配内核本身所需的内存，包括代码、数据和堆栈部分。然后创建一个具有适当的地址和功能空间的初始用户线程。然后，内核将所有剩余内存以非类型化内存的功能形式交给初始线程，并将引导初始线程所需的一些额外的内核对象功能交给初始线程。然后可以使用seL4 Untyped Retype()方法将这些非类型化内存区域分割为更小的区域或其他内核对象，创建的对象被称为原始无类型内存对象的子对象。

使用seL4 Untyped Retype()创建对象的用户级应用程序，将接收对结果对象的全部权限。然后，它可以将其对该对象拥有的全部或部分权限委托给一个或多个客户端。

非类型化内存对象表示两种不同类型的内存：通用内存或设备内存。
通用内存可以非类型化为任何其他对象类型，并接受内核提供的非类型化内存上的任何操作。设备内存覆盖由硬件平台决定的为设备预留的内存区域，这些对象的使用受到内核以下方式的限制:

1. 设备非类型化对象只能重新键入到帧或其他非类型化对象中；例如，开发人员不能从设备内存创建端点；
2. 从设备中重新类型化的帧对象不能设置为线程IPC缓冲区，或用于创建ASID池；

子无类型对象的类型属性继承自父亲的无类型对象，也就是说，未类型化设备的任何子设备也将是一个未类型化设备。开发人员不能更改无类型的类型属性。

#### 总结

seL4操作系统微内核在达到了极高的安全标准的同时兼顾了良好的性能，其微内核式的设计也为其向各个平台移植打下了坚实的基础。seL4的开源有利于本项目进行深入研究、探讨、参考和借鉴。目前暂定的seL4借鉴内容有：微内核结构、安全性实现、访问控制与进程隔离；要进行修改的内容有：进程间mmap通信、在浏览器环境下运行、rust语言编写。



### **分布式数据管理**

####  概述[^9]

分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。  

分布式数据管理（DDM）是操作系统的一种功能，允许一个系统上的应用程序或用户使用存储在远程系统上的数据库文件。该系统必须连接通信网络，远程系统必须也使用 DDM。  

借助服务器上的 DDM，应用程序或用户可执行下列任务：

- 访问驻留在远程系统（目标系统）上的数据文件。远程系统也可以访问本地系统上的数据文件。
- 应用程序可以添加、更改和删除目标系统上存在的文件中的数据记录。
- 创建、删除或重命名远程系统上的文件。
- 将文件从一个系统复制到另一个系统。

使用 DDM 时，应用程序和程序用户都不必知道所需的文件是在本地系统上还是在远程系统上。远程文件处理和本地文件处理基本上是按相同的方式来处理的。    

#### CAP原理和最终一致性[^10]

##### CAP原理(CAP Theorem)

在足球比赛里，一个球员在一场比赛中进三个球，称之为帽子戏法(Hat-trick)。在分布式数据系统中，也有一个帽子原理(CAP Theorem)，不过此帽子非彼帽子。CAP原理中，有三个要素：

1）一致性(Consistency)

2）可用性(Availability)

3）分区容忍性(Partition tolerance)

CAP原理指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。

因此在进行分布式架构设计时，必须做出取舍。而对于分布式数据系统，分区容忍性是基本要求 ，否则就失去了价值，因此设计分布式数据系统，就是在一致性和可用性之间取一个平衡。

对于大多数web应用，其实并不需要强一致性，因此牺牲一致性而换取高可用性，是目前多数分布式数据库产品的方向。

当然，牺牲一致性，并不是完全不管数据的一致性，否则数据是混乱的，那么系统可用性再高分布式再好也没有了价值。

牺牲一致性，只是不再要求关系型数 据库中的强一致性，而是只要系统能达到最终一致性即可，考虑到客户体验，这个最终一致的时间窗口，要尽可能的对用户透明，也就是需要保障“用户感知到的一致性”。

通常是通过数据的多份异步复制来实现系统的高可用和数据的最终一致性的，“用户感知到的一致性”的时间窗口则 取决于数据复制到一致状态的时间。

##### 最终一致性(eventually consistent)

对于一致性，可以分为从客户端和服务端两个不同的视角。

从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。

从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。

一致性是因为有并发读写才有的问题，因此在理解一致性的问题时，一定要注意结合考虑并发读写的场景。

从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。

对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性 ；如果能容忍后续的部分或者全部访问不到，则是弱一致性 ； 如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。

从服务端角度，如何尽快将更新后的数据分布到整个系统，降低达到最终一致性的时间窗口，是提高系统的可用度和用户体验非常重要的方面。

那么问题来了，如何实现数据的最终一致性呢？答案就在事件驱动架构。

#### 事件驱动架构简介[^10]

Chris Richardson作为微服务架构设计领域的权威，给出了分布式数据管理的最佳解决方案。

对于大多数应用而言，要实现微服务的分布式数据管理，需要采用事件驱动架构（event-driven architecture）。

在事件驱动架构中，当某件重要事情发生时，微服务会发布一个事件，例如更新一个业务实体。

当订阅这些事件的微服务接收此事件时，就可以更新自己的业务实体，也可能会引发更多的事件发布，让其他相关服务进行数据更新，最终实现分布式数据最终一致性。

可以使用事件来实现跨多服务的业务交易。交易一般由一系列步骤构成，每一步骤都由一个更新业务实体的微服务和发布激活下一步骤的事件构成。

#### 事件驱动示例[^11]

下图展现如何使用事件驱动方法，在创建订单时检查信用可用度，微服务之间通过消息代理（Message Broker）来交换事件。

1. 订单服务创建一个带有NEW状态的Order （订单），发布了一个“Order Created Event（创建订单）”的事件。

![oce](https://cdn.wp.nginx.com/wp-content/uploads/2015/12/Richardson-microservices-part5-credit-check-1-e1449727610972.png)

2. 客户服务 消费Order Created Event事件，为此订单预留信用，发布“Credit Reserved Event（信用预留）”事件。

![Credit Reserved Event](https://cdn.wp.nginx.com/wp-content/uploads/2015/12/Richardson-microservices-part5-credit-check-2-e1449727579423.png)

3. 订单服务消费Credit Reserved Event，改变订单的状态为OPEN。

![creopen](https://cdn.wp.nginx.com/wp-content/uploads/2015/12/Richardson-microservices-part5-credit-check-3-e1449727548440.png)

####　事件驱动架构之分布式数据更新[^10]

上节通过示例概要介绍了通过事件驱动方式，实现了分布式数据最终一致性保证。纵观微服务架构下的事件驱动业务处理逻辑，其核心要点在于，可靠的事件投递和避免事件的重复消费。

可靠事件投递有以下两个特性：

 1) 每个服务原子性的完成业务操作和发布事件；

 2) 消息代理确保事件投递至少一次(at least once)；

而避免事件重复消费则要求消费事件的服务实现幂等性，比如支付服务不能因为重复收到事件而多次支付。

#####  如何实现事件投递操作原子性？

事件驱动架构会碰到数据库更新和发布事件原子性问题。例如，订单服务必须向ORDER表插入一行，然后发布Order Created event，这两个操作需要原子性。比如更新数据库后，服务瘫了（crashes）造成事件未能发布，系统变成不一致状态。那么如何实现服务的业务操作和发布事件的原子性呢？

###### 使用本地事务发布事件

获得原子性的一个方法是将服务的业务操作和发布事件放在一个本地数据库事务里，也就是说，需要在本地建立一个EVENT表，此表在存储业务实体数据库中起到消息列表功能。当应用发起一个（本地）数据库交易，更新业务实体状态时，会向EVENT表中插入一个事件，然后提交此次交易。另外一个独立应用进程或者线程查询此EVENT表，向消息代理发布事件，然后使用本地交易标志此事件为已发布，如下图所示：

![event table](https://cdn.wp.nginx.com/wp-content/uploads/2015/12/Richardson-microservices-part5-local-transaction-e1449727484579.png)

订单服务向ORDER表插入一行，然后向EVENT表中插入Order Created event，事件发布线程或者进程查询EVENT表，请求未发布事件，发布他们，然后更新EVENT表标志此事件为已发布。

此方法也是优缺点都有。优点是可以确保事件发布不依赖于2PC，应用发布业务层级事件而不需要推断他们发生了什么；而缺点在于此方法由于开发人员必须牢记发布事件，因此有可能出现错误。

###### 使用事件源

Event sourcing （事件源）通过使用以事件中心的数据存储方式来保证业务实体的一致性。事件源保存了每个业务实体所有状态变化的事件，而不是存储实体当前的状态。应用可以通过重放事件来重建实体现在的状态。只要业务实体发生变化，新事件就会添加到事件表中。因为保存事件是单一操作，因此肯定是原子性的。

为了理解事件源工作方式，考虑以事件实体作为一个例子说明。传统方式中，每个订单映射为ORDER表中一行。但是对于事件源方式，订单服务以事件状态改变方式存储一个订单：创建的，已批准的，已发货的，取消的；每个事件包括足够信息来重建订单的状态。

![Event source](https://cdn.wp.nginx.com/wp-content/uploads/2015/12/Richardson-microservices-part5-event-sourcing-e1449711558668.png)

事件源方法有很多优点：解决了事件驱动架构关键问题，使得业务实体更新和事件发布原子化，但是也存在缺点，因为是持久化事件而不是对象，导致数据查询时，必须使用 Command Query Responsibility Segregation (CQRS) 来完成查询业务，从开发角度看，存在一定挑战。

####　事件驱动架构优缺点[^10]

事件驱动架构既有优点也有缺点，此架构可以实现跨多个服务的事务实现，且提供最终数据一致性，并且使得服务能够自动维护查询视图；而缺点在于编程模式比传统基于事务的交易模式更加复杂，必须实现补偿事务以便从应用程序级故障中恢复，例如，如果信用检查不成功则必须取消订单；另外，应用必须应对不一致的数据，比如当应用读取未更新的最终视图时也会遇见数据不一致问题。另外一个缺点在于订阅者必须检测和忽略冗余事件，避免事件重复消费。



### **跨平台技术典例**

#### 基本概念[^14]

跨平台泛指程序语言、软件或硬件设备可以在多种作业系统或不同硬件架构的电脑上运作。

广义而言，一般的计算语言都可做到跨平台，开发商只需要提供各种平台下的Runtime/中间件环境即可。严格而言是指用某种计算机语言编制的程序只需要做小量的修改，编译之后即可在另外一种平台下运行，此时并不提供Runtime/中间件环境。



#### JAVA实现跨平台[^12]

Java对于跨平台的支持，就像对安全性和网络移动性的支持一样，是分布在整个Java体系结构中的。其中扮演者重要的角色的有 **Java语言规范、Class文件、Java虚拟机（JVM）**等。

首先，在Java语言规范中，规定了Java语言中基本数据类型的取值范围和行为。其次，所有Java文件要编译成统一的Class文件。最后，通过Java虚拟机将Class文件转成对应平台的二进制文件。

想把Java文件，编译成二进制文件文件，需要经过两步编译，**前端编译**和**后端编译**。

![前后端编译示意图](https://camo.githubusercontent.com/a2e2815a2d9ad21076fb0801e276a9cea93dfc2b/68747470733a2f2f7777772e686f6c6c6973636875616e672e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031392f30332f31353533393239313533333137352e6a7067)

前端编译主要是指与源语言有关但与目标机无关的部分。Java中，我们知道的 javac 的编译就是前端编译。除了这种以外，我们使用的很多IDE如eclipse，idea等，都是内置了前端编译器，主要功能就是.java文件转换为.class文件。

后端编译主要是将中间代码再翻译成机器语言。Java中，这一步骤就是后端编译（jvm来执行）。

#####  Java语言规范

Java语言在跨平台方面做了一些努力，这些努力被定义在Java语言规范中。遵从规范格式，才能够被jvm编译以及解释运行。比如，Java中基本数据类型的值域和行为都是由其自己定义的。而C/C++中，基本数据类型是由它的占位宽度决定的，占位宽度则是由所在平台决定的。所以，在不同的平台中，对于同一个C++程序的编译结果会出现不同的行为。 

*注：举一个简单的例子，对于int类型，在Java中，int占4个字节，这是固定的。 但是在C++中却不是固定的了。在16位计算机上，int类型的长度可能为两字节；在32位计算机上，可能为4字节；当64位计算机流行起来后，int类型的长度可能会达到8字节。*

##### Class字节码

各种不同的平台的虚拟机都使用统一的程序存储格式——字节码（ByteCode），这是构成平台无关性的另一个基石。Java虚拟机只与由字节码组成的Class文件进行交互。 我们说Java语言可以Write Once ,Run Anywhere。这里的Write其实指的就是生成Class文件的过程。 因为Java Class文件可以在任何平台创建，也可以被任何平台的Java虚拟机装载并执行，所以才有了Java的平台无关性。Class 是16进制的文件流，最终会被jvm转成二进制的机械码。

##### JAVA虚拟机

Java的平台无关性是建立在Java虚拟机的平台有关性基础之上的，是因为Java虚拟机屏蔽了底层操作系统和硬件的差异。

跨平台是由jvm来完成的，jvm会根据不同的操作系统和硬件设备，提供不同jvm。想要做到跨平台，最重要的就是根据对应的硬件和操作系统生成Class文件对应的二进制指令。

*HotSpot虚拟机中，主要有解释执行和即时编译两种形式：*

*1. 解释执行：逐条将字节码翻译成机器码并执行*

*2. 即时编译（Just-in-time ，JIT）：将一个方法中包含的所有字节码编译成机器码后再执行。*

*HotSpot 默认采用混合模式，综合了解释执行和即时编译两者的优点。它会先解释执行字节码，而后将其中反复执行的热点代码（热点检测），以方法为单位进行即时编译。*



#### Android实现跨平台[^13]

<img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fcollection.sinaimg.cn%2Fcqyw%2F20121016%2FU5566P1081T2D88572F7DT20121016095448.gif&refer=http%3A%2F%2Fcollection.sinaimg.cn&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1620637454&t=19d4c61edfb40c097ee2a942b55ab73e" width="30%">



Android也是基于Java语言的，Android源代码转换成机器码这一过程随着版本有不少的优化：

* Android 1.0（2008 年）：采用一个名为 Dalvik 的虚拟机，并且集成了一个解释器。当 App 运行时，就会调用这个解释器，对代码进行逐句解释，速度很慢。

* Android 2.2（2010 年）：引入 JIT（Just In Time）即时编译机制，当 App 运行时，会将用户经常使用的功能编译为机器能直接执行的 010101 机器码，不用一句一句地去翻译。当出现不常用的功能时，再调用解释器来翻译；这样速度加快，但每次启动 App 都要重新编译一次，不能一劳永逸。

* Android 5.0（2014 年 10 月）：将虚拟机 Dalvik 换成 ART（Android Run Time），将 JIT 的编译器替换成 AOT（Ahead of Time）。如此，App 在下载后安装到手机上时同时把能编译的代码先编译成机器听得懂的 101010；剩下不太好翻译的代码，就在用户使用时再叫醒解释器来翻译。如此，不用每次打开 App 都需要编译，但安装 App 的时间有点长，而且占用手机空间。

* Android 7.0（2016 年）：采用混合编译机制，安装时先不编译中间代码，而是在用户空闲时将能够编译成机器码的那部分代码，通过 AOT 编译器先静态编译了。如果 AOT 还没来得及编译或者不能编译，再调用 JIT+ 解释器。这种机制，相当于用时间换空间，既缩短了用户安装 APP 的等待时间，又将虚拟机里编译器和解释器能做的优化提升到最大效率了。

* Android 8.0 上改进了解释器，解释模式执行效率大幅提升。

* Android 10.0 上提供了预先放置热点代码的方式，应用在安装的时候就能知道常用代码会被提前编译。

  当前的 Android 采用的是解释执行 + JIT + AOT 的综合模式，在 空间占用+安装速度+运行速度 上已经达到了一个很好的平衡。但应用在被打包成 APK 的时候，采用的还是 Java 代码。换句话说，在 APK 变成用户可应用的过程中，还经历了一个在 Android 系统内部的编译过程。

  

#### 鸿蒙OS实现跨平台[^13]

![](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/C1uDMDqjn1ibEXMVp5gicrRHq5ibFJwLxTLw44agsAJ03FThg4Z1ia781maz0Bq9efOkZ3K3ZQuqFF577KM7bXXZ1Q/640?wx_fmt=jpeg)

如图所示，在鸿蒙OS架构中，**方舟编译器**和**多终端开发IDE**扮演着重要的位置。

##### 多终端开发IDE

使用华为提供的多终端IDE，多语言统一编译，分布式架构Kit提供屏幕布局控件以及交互的自动适配，支持控件拖拽，面向预览的可视化编程，从而使开发者可以基于同一工程高效构建多端自动运行APP，实现真正的一次开发，多端部署，在跨设备之间实现共享生态。在IDE里面可以通过图形化界面拖拽控件，并且IDE可以帮助自动适配各种终端设备。

##### 方舟编译器

华为方舟编译器是首个取代Android虚拟机模式的静态编译器，可供开发者在开发环境中一次性将高级语言编译为机器码。此外，方舟编译器未来将支持多语言统一编译，可大幅提高开发效率。

![](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/C1uDMDqjn1ibEXMVp5gicrRHq5ibFJwLxTLVHJlMUrHh9SBGniav72D5CGtmGv5q4ZcGByvw5qglh0Bly0mOtTEm6A/640?wx_fmt=jpeg)

Android之所以"慢"，是因为他的编译过程是在终端进行的，也就是说需要在用户的手机上，通过虚拟机进行编译成可执行的机器代码。而方舟编译器绕过了虚拟机，在应用开发阶段就完成编译过程。开发者的应用在下载之前就已经转化成为机器可以识别的代码，因而可以在手机上快速安装、启动和运行，而无需在经过 VM 的编译——某种程度上，方舟编译器是将编译过程提前到应用开发阶段，从而大幅度减少了智能手机和操作系统的运行负担。



### **系统移植**

#### Linux系统移植的两大部分[^15]

**内核部分**和**系统部分**

* 内核部分初始化和控制所有硬件设备(严格说不是所有，而是绝大部分)，为内存管理、进程管理、设备读写等工作做好一切准备。

* 系统部分加载必需的设备，配置各种环境以便用户可以使用整个系统。

#### Linux系统移植需要的环境

首先，需要一个新版本的gcc。

其次，编译链接库是必需的，而且必须是目标平台的编译链接库。

最后，需要目标平台的所有文档，越多越好。

#### Linux系统移植

##### 内核移植

Linux系统采用了相对来说并不是很灵活的单一内核机制，但这丝毫没有影响Linux系统的平台无关性和可扩展性。Linux使用了两种途径分别很干净利落地解决了这些问题。

* 分离硬件相关代码和硬件无关代码，使上层代码永远不必关心低层换用了什么代码，如何完成了操作。不论对x86上还是在Alpha平台上分配一块内存，对上层代码而言没什么不同。硬件相关部分的代码不多，占总代码量的很少一部分。所以对更换硬件平台来说，没有什么真正的负担。
* 使用内核机制很好地解决了扩展的问题，一堆代码可以在需要的时候轻松地加载或卸下，象随身听，需要的时候带上，不需要时则锁在抽屉里。

Linux内核可以视为由五个功能部分组成：进程管理(包括调度和通信)、内存管理、设备管理、虚拟文件系统、网络。它们之间有着复杂的调用关系，但幸运的是，在移植中不会触及到太多，因为Linux内核良好的分层结构将硬件相关的代码独立出来。何谓硬件相关，何谓无关?以进程管理为例，对进程的时间片轮转调度算法在所有平台的Linux中都是一样的，它是与平台无关的;而用来在进程中切换的实现在不同的CPU上是不同的，因此需要针对该平台编写代码，这就是平台相关的。上面所讲的五个部分的顺序不是随便排的，从前到后分别代表着它们与硬件设备的相关程度。越靠前越高，后面的两个虚拟文件系统和网络则几乎与平台无关，它们由设备管理中所支持的驱动程序提供底层支持。因此，在做系统移植的时候，需要改动的就是进程管理、内存管理和设备管理中被独立出来的那部分即硬件相关部分的代码。在Linux代码树下，这部分代码全部在arch目录下。

如果你的目标平台已经被Linux核心所支持的话，那么你是幸运的，因为已经没有太多的工作让你去做。只要你的交叉编译环境是正确的，你只需要简单的配置、编译就可以得到目标代码。否则，需要你去编写，或修改一些代码。只需修改平台相关部分的代码即可。但需要对目标平台，主要是对CPU的透彻理解。在Linux的代码树下，可以看到，这部分的典型代码量为：2万行左右C代码和2千行左右的汇编(C代码中通常包含许多伪汇编指令，因此实际上纯C代码要少很多)，这部分工作量是不可小看的。它包含了对绝大多数硬件的底层操作，涉及IRQ、内存页表、快表、浮点处理、时钟、多处理器同步等问题，频繁的端口编程意味着需要你将目标平台的文档用C语言重写一遍。这就是为什么说目标平台的文档极其重要。

代码量大的部分是被核心直接调用的底层支持部分，这部分代码在arch/xxx/kernel下(xxx是平台名称)。这些代码重写了内核所需调用的所有函数。因为接口函数是固定的，所以这里更象是为硬件平台编写API。不同的系统平台，主要有以下几方面的不同：

* 进程管理底层代码：从硬件系统的角度来看，进程管理就是CPU的管理。在不同的硬件平台上，这有很大的不同。CPU中用的寄存器结构不同，上下文切换的方式、现场的保存和恢复、栈的处理都不同，这些内容主要由CPU开发手册所描述。通常来说，CPU的所有功能和状态对于Linux不一定有意义。实现时，需要在小的开发代价和好的系统性能之间加以权衡。

* BIOS接口代码：这一名称似乎并不太准确，因为它沿用了PC一贯的叫法。但在不致引起混淆的情况下我们还是这么叫它。在通用平台上，通常有基本输入输出系统供操作系统使用，在PC上是BIOS，在SPARC上是PROM，在很多非通用系统上甚至并没有这样的东西。多数情况下，Linux不依赖基本输入输出系统，但在某些系统里，Linux需要通过基本输入输出系统中得到重要的设备参数。移植中，这部分代码通常需要完全改写。

* 时钟、中断等板上设备支持代码：即使在同一种CPU的平台上，也会存在不同的板上外设，异种CPU平台上更是如此。不同的系统组态需要不同的初始化代码。很典型的例子就是MIPS平台，看看arc/mips/的代码，与其它系统比较一下就知道。因为MIPS平台被OEM得广，在嵌入式领域应用多(相对其它几种CPU而言)。甚至同一种MIPS芯片被不同厂家封装再配上不同的芯片组。因此要为这些不同的MIPS平台分别编写不同的代码。

* 特殊结构代码：如多处理器支持等。其实每一种CPU都是十分特殊的，熟悉x86平台的人都知道x86系列CPU著名的实模式与虚模式的区别，而在SPARC平台上根本就没有这个概念。这就导致了很大的不同：PC机上的Linux在获得控制权后不久就开始切换到虚模式，SPARC机器上则没有这段代码。又如电源管理的支持更是多种多样，不同的CPU有着不同的实现方式(特殊的电源管理方式甚至被厂商标榜)。在这种情况下，除非放弃对电源管理的支持，否则必须重写代码。

还有一部分代码量不多，但不能忽视的部分是在arch/xxx/mm/下的内存管理部分。所有与平台相关的内存管理代码全部在这里。这部分代码完成内存的初始化和各种与内存管理相关的数据结构的建立。Linux使用了基于页式管理的虚拟存储技术，而CPU发展的趋势是：为了提高性能，实现内存管理的功能单元统统被集成到CPU中。因此内存管理成为一个与CPU十分相关的工作。同时内存管理的效率也是影响系统性能的因素之一。内存可以说是计算机系统中频繁访问的设备，如果每次内存访问时多占用一个时钟周期，那就有可能将系统性能降低到不可忍受。在Linux系统里，不同平台上的内存管理代码的差异程度是令人吃惊的，可以说是差异大的。不同的CPU有不同的内存管理方式，同一种CPU还会有不同的内存管理模式。Linux是从32位硬件平台上发展起来的操作系统，但是现在已经有数种64位平台出现。在64位平台上，可用内存范围增大到原来的232倍，其间差异可略窥一斑了。鉴于这部分代码的重要性和复杂性，移植工作在这里变得相当谨慎。有些平台上甚至只是用保守的内存管理模式。如在SPARC平台上的页面大小可以是多种尺寸，为了简单和可靠起见，SPARC版的Linux只是用了8K页面这一种模式。这一状况直到2.4版才得以改善。

除此之外，还有一些代码需要考虑，但相对来说次要一些。如浮点运算的支持。较完美的做法是对FPU编程，由硬件完成浮点运算。但在某些时候，浮点并不重要，甚至CPU根本就不支持浮点。这时候就可以根据需求来取舍。

实际上，还有一些移植工作需要同时考虑，但很难说这是属于内核范畴还是属于驱动程序范畴，比如说显示设备的支持，和内核十分相关，但在逻辑上又不属于内核，并且在移植上也更像是驱动程序的开发。

##### 系统移植

当内核移植完毕后，可以说所有的移植工作就已经完成大半了。就是说，当内核在交叉编译成功后，加载到目标平台上正常启动，并出现类似VFS: Can't mount root file system的提示时，则表示可以开始系统移植方面的工作了。系统移植实际上是一个小系统的重建过程。许多Linux爱好者有过建立Linux系统应急盘的经验，与其不同的是，你需要使用目标平台上的二进制代码生成这个小系统。包括：init、libc库、驱动模块、必需的应用程序和系统配置脚本。一旦这些工作完成，移植工作就进入联调阶段了。

一个比较容易的系统部分移植办法是：先着手建立开发平台上的小系统，保证这套小系统在开发平台上正确运行。这样可以避免由于小系统本身的逻辑错误而带来的麻烦。由于小系统中是多个应用程序相互配合工作，有时出现的问题不在代码本身而在系统的逻辑结构上。



### **微内核性能**

#### 微内核性能低下的原因[^16]

微内核操作系统，与主流宏内核OS相比，一直存在性能较为低下的问题。其主要原因如下：

+ **IPC性能瓶颈**
  进程间通信（IPC）成本是改进微内核性能的主要工作重点。微内核IPC导致内核态、用户态的频繁切换，它比其他因素的影响要大得多。
+ **上下文切换开销大**
  对于一些频繁的操作，例如网络化，上下文切换的开销对于内核实现来说太大了。
+ **RPC成本高**
  在用户态下运行以前内核集成的服务，需要在内核或客户端使用服务时，使用远程过程调用(RPC)。而RPC的时间成本比对内核的简单系统调用要高得多。
+ **内存引用成本高**
  内存引用的成本，可以用每个指令的内存周期（MCPI）衡量。跑同样的程序，微内核比宏内核MCPI高得多。而这又是因为：一，微内核代码的局部性差。二，系统错误地缓存高速缓存行。三，高度模块化导致的模块间复制。

#### 提升微内核效率的思路

1.套接字（Socket）通信机制

2.共享内存（Shared Memory/ Memory Map）机制

3.减少模块频繁装卸

#### Socket[^17]

##### 基本概念

<img src="https://images.cnblogs.com/cnblogs_com/goodcandle/socket2.jpg" width=70%/>

Socket是调用操作系统通信服务的一种机制。它上联应用进程，下联网络协议栈，本质上是一组接口（API）。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，只调用Socket接口来使用下层TCP/IP提供的服务，如上图所示。

Socket API可以看作是应用程序与运输层之间的一座桥梁，看作应用程序与操作系统的通信服务之间的协议。Socket主要分为三类：流套接字(SOCK_STREAM)，数据报套接字(SOCK_DGRAM)，原始套接字(SOCK_RAW)。

##### 运行机制

<img src="http://images.jackailiu.com/editor/201908/156605164049363.png" width=100% />

Socket不仅作为本地进程间通信的一种机制，还广泛地应用于网络上不同机器间的通信。通信的两个主体各自被操作系统分配一个创建的Socket，它主要有三个参数：通信的目的IP address，使用的传输层协议(TCP or UDP)，和使用的端口号port。两端的两个Socket构成一个双向传输信息的链路。

##### 借鉴应用

Socket起源于Unix，最先应用Socket的操作系统就是Unix。而Unix/Linux基本哲学之一就是“一切皆文件”，都可以用“ 打开open –> 读写write/read –> 关闭close ”模式来操作。Socket程序编写的基本思路就是：Socket看作是一种特殊的文件，一些Socket函数就是对其进行的操作（读/写IO、打开、关闭）。

一般的，Socket常用于宏内核IPC，而微内核利用消息队列机制来实现IPC，众多微内核操作OS的典型IPC机制也就是消息机制。因此，考虑参照linux等已经以Socket方式实现IPC的操作系统，对改造目标（inferno）进行移植。

#### Mmap[^18]

##### 基本概念

mmap是一种内存映射文件的方法，即将硬盘文件映射到进程的虚拟地址空间，实现文件磁盘地址和地址空间中一段虚拟地址的一一对映关系。当从缓冲区中取数据，就相当于读文件中的相应字节；将数据存入缓冲区，则相应的字节就自动写入文件。

而共享内存机制，即是允许两个或多个进程共享内存映射。在上述mmap内存映射中，将多个进程的虚拟地址映射为同一个物理地址。

##### 运行机制

<img src="https://img-blog.csdn.net/20180416112848158" width=100%/>

1. 进程启动映射过程，并在虚拟地址空间中找一段空闲的，创建虚拟映射区域；
2. 调用内核空间的系统调用函数mmap（不同于用户空间函数），建立文件物理地址和进程虚拟地址的link；
3. 进程发起对这片映射空间的访问。由于上一步骤只有映射的建立，没有文件数据的拷贝，要访问却找不到物理地址，引发缺页异常。于是内核发起调页，实现文件内容到物理内存的拷贝。

##### 借鉴应用

微内核操作系统Mach使用mmap机制来完成IPC。Mach 的机制只有需要对内存进行写入时才进行复制，比每次都复制一遍内存节省了内存使用，同时又加快了IPC机制的处理时间。这个改进称为写时复制，并且在如今的通用操作系统，如Linux 中常常用到。

该机制不需借助read/write函数，提高了通信效率；与常规文件操作相比，跳过了页缓存这一中转，步骤省去了一次数据拷贝；映射时以页为单位，简化了内存管理。安全性上，保护了每个进程的地址空间不被其他进程破坏。共享内存机制是目前速度最快的IPC机制，可将之应用于inferno IPC的改进。

####	模块装卸过程优化[^19,20]

微内核架构包含两类组件：核心系统（Core System）和插件模块（Plug-in Modules）。核心系统负责和具体业务功能无关的通用功能，例如模块加载、模块间通信等；插件模块负责实现具体的业务逻辑。
以上的Socket和Mmap机制，提供了增加IPC性能的思路。而针对频繁模块装卸带来的效率降低，可以考虑如下两方面：

#####	寻找宏微内核间的平衡

严格意义上的微内核仅包含最基础的功能模块。将核心功能模块化，划分成几个独立的进程，各自运行。而宏内核，则是将大量功能模块都集中到内核态。为寻求两者之间的妥协、平衡，混合内核的概念被提出。
混合内核以微内核架构来设计操作系统核心，但在实现上则采用宏内核的做法。为了追求性能，将需要具备特权的服务组件放进核心空间，即成为混合内核。

目前的微内核操作系统，大多实际上属于混合内核。Linux属于单内核，兼具宏微内核各自的优点，引入了动态可加载内核模块，模块可以在系统运行期间加载到内核或从内核卸载。

因此，可以对目标（inferno）的插件模块进行权衡，将频繁使用的关键模块移至内核态运行，减少不必要的内核态、用户态切换，提升效率。

##### 优化模块加载与卸载的管理

微内核OS用插件注册表机制对插件模块进行管理。其功能包括：插件管理，插件与内核的连接，插件间通信。注册表包含每个插件模块的信息，如名字、位置、加载时机等，可以是配置文件、代码或数据库。基于注册表，可以对微内核模块管理系统做出优化[4]。

例如，通过对注册表的读取与分析，可以对模块加载和卸载的情况进行统计。设计调度机制和预测算法，根据各插件生命周期的规律，作出预测，减少高频使用模块的卸载。

### **Rust语言**                                                                                       ![Rust](https://www.rust-lang.org/static/images/rust-logo-blk.svg)

#### 简介[^23]

Rust是一门系统编程语言 ，专注于安全 ，尤其是并发安全，支持函数式和命令式以及泛型等编程范式的多范式语言。Rust在语法上和[C++](https://baike.baidu.com/item/C%2B%2B/99272)类似，但是设计者想要在保证性能的同时提供更好的内存安全。Rust最初是由Mozilla研究院的Graydon Hoare设计创造，然后在Dave Herman, Brendan Eich以及很多其他人的贡献下逐步完善的。Rust的设计者们通过在研发Servo网站浏览器布局引擎过程中积累的经验优化了Rust语言和Rust编译器。

#### 性能[^22]

Rust非常快并且拥有高效率的内存访问：没有运行时和垃圾收集器。它可以为性能要求较高的应用提供支持、可以在嵌入式设备上运行、并且可以轻松地与其他语言集成。

#### 可靠性[^22]

Rust丰富的类型系统和所有权模型保证了内存安全性和线程安全性，使得很多不安全错误在编译时就能被发现并被修正。在保障性能的同时克服了C语言内存易泄露、指针易出错的问题。

#### 生产效率[^22]

Rust拥有出色的文本编辑器、友好的编译器、有用的错误信息以及一流的工具-集成的软件包管理器和构建工具，具有自动补全、类型检查和自动格式化程序等功能的智能编辑器。

## **立项依据与重要性分析**

1. **微内核发展现状**：微内核结构是1980年代产生出来的较新的内核结构，强调结构性部件与功能性部件的分离。20世纪末，基于微内核结构，理论界中又发展出了超微内核与外内核等多种结构。目前主流的微内核为第二代微内核，以L4系列为代表，收到广泛欢迎，其中开源的seL4也为我们提供了重要的参考依据；而各大商用操作系统也在考虑其微内核化，微内核未来市场潜力巨大。并且微内核代码量较小，适合作为学期任务进行。因此，我们选择进行微内核项目。[^图片来源][^21]![微内核与宏内核对比](https://upload-images.jianshu.io/upload_images/4324074-82eb29cce869b546.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

2. **Inferno发展现状**：Inferno的出现标志着分布式操作系统的诞生：通过外设与与许多用户相连的一个中央计算系统结构已经落伍，取而代之的是用户可从本地工作站连接到许多计算机网络的集合的分布式架构。Inferno通过Styx协议，将请求化为函数调用，通过模糊本地与远程服务的区别，实现便捷地调用分布式计算资源。这样的实现将很好地解决微内核操作系统性能的瓶颈IPC效率过低的问题，从而整体上提高微内核操作系统的工作性能。

   但Inferno最后的更新版本是2004年的Inferno第四版，此后再无更新，这就意味着近些年取得新突破的技术未在Inferno得以体现，也同时意味着现在的Inferno早已落伍。我们考虑在Inferno这样一个具有优秀的设计理念的操作系统上，用Rust重写以提升其安全性，考虑分布式数据管理的事件驱动架构实现数据最终一致性，同时在Inferno原有的移植性上进一步开发跨平台和系统移植性。

3. **Rust安全性**：Rust丰富的类型系统和所有权模型保证了内存安全性和线程安全性，使得很多不安全错误在编译时就能被发现并被修正。在保障性能的同时克服了C语言内存易泄露、指针易出错的问题。

4. **操作系统安全性需求**：操作系统不安全，是计算机不安全的重要原因。面临名目繁多的计算机病毒威胁计算机病毒将导致计算机系统瘫痪，程序和数据严重破坏，使网络的效率和作用大大降低，使许多功能无法使用或不敢使用。虽然，至今尚未出现灾难性的后果，但层出不穷的各种各样的计算机病毒活跃在各个角落，令人担忧。seL4作为一款安全性经过形式验证的操作系统微内核，适应了市场的需求，是本项目的重要参考。

5. **操作系统微内核性能需求**[^25]：微内核在操作系统架构方面做出了革新，同时也带来了效率问题。Mach是最早的微内核系统，却因性能低下而没落。传统Unix系统的系统调用比Mach 3的类RPC调用快大约10倍。第二代微内核（如L4，Exokernel）做出了IPC机制改进，但并未解决MCPI问题，在多服务器上的性能也不如人意。第三代微内核中，seL4在当今微内核中性能最高，其优化方法值得参考。微内核系统只有性能得到了保证，才能更广泛地投入应用。

   Inferno作为第二代微内核操作系统，通过Sytx改进了IPC机制。但是，该系统早已停止更新，未能跟上将第三代微内核的发展潮流。因此，inferno在效率提升方面有着改进的空间和需求。

6. **操作系统跨平台方面需求**[^24]：现在平台的种类越来越多，PC端有Windows,Linux, MacOS等等，移动端有Android，iOS等等，在程序开发过程中面临不同操作系统需不同开发语言，同一操作系统存在不同版本，同一版本存在不同机型等难题传统的纯原生开发已经不能满足日益增长的业务需求。

   一方面动态化内容需求增大。当需求发生变化时，纯原生应用需要通过版本升级来更新内容，但应用上架、审核是需要周期的，这个周期对高速变化的互联网时代来说是很难接受的，所以对应用动态化(不发版也可以更新应用内容)的需求就变得迫在眉睫了。

   另一方面需求变化快，开发成本变大。原生开发一般都有维护多个版本的开发团队，版本迭代时，针对不同的端去编写多套代码的成本非常高，这时候只编写一套代码就能够适配到多端的能力就显得极为需要，否则无论人力成本还是测试成本都会变大。

   因此在开发领域，跨平台开发技术成为很多企业和开发者的首选，可以有效解决不同操作系统不同机型终端的开发难题，节省时间成本和人员成本。

7. **操作系统分布式管理需求**：分布式数据管理的优势主要在以下几个方面：

   （1）具有灵活的体系结构
   （2）经济性能优越	
   （3）系统的可靠性高、可用性好
   （4）局部应用的响应速度快
   （5）可扩展性好，易于集成现有系统。

   分布式数据管理可应用于特别是大规模的数据存储与高并发访问的行业应用，如大型应用、物联网数据、文件索引、高性价比数据库解决方案等应用场景。



## ***参考文献***

[^1]: seL4官网 https://sel4.systems/index.html
[^2]: seL4手册：内核服务与对象 https://blog.csdn.net/weixin_38849460/article/details/112788571
[^3]:seL4白皮书 https://sel4.systems/About/seL4-whitepaper.pdf
[^4]:分布式操作系统简介 https://blog.csdn.net/qq_33880788/article/details/79476715?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161789831016780255249738%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161789831016780255249738&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-4-79476715.pc_search_result_hbase_insert&utm_term=%E5%88%86%E5%B8%83%E5%BC%8F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F&spm=1018.2226.3001.4449
[^5]:Distributed_Operating_System https://en.wikipedia.org/wiki/Distributed_operating_system
[^6]:Inter-Process Communication https://en.wikipedia.org/wiki/Inter-process_communication
[^7]:Inferno OS https://zh.wikipedia.org/wiki/Inferno
[^8]:Plan 9 https://zh.wikipedia.org/wiki/%E8%B2%9D%E7%88%BE%E5%AF%A6%E9%A9%97%E5%AE%A4%E4%B9%9D%E8%99%9F%E8%A8%88%E7%95%AB
[^9]:分布式数据管理概念 https://www.ibm.com/docs/zh/i/7.1?topic=applications-distributed-data-management
[^10]:微服务架构下的分布式数据管理 https://mp.weixin.qq.com/s/WYNrcBe0h_o7whRGxqsqwg
[^11]:Event-Driven Data Management for Microservices https://www.nginx.com/blog/event-driven-data-management-microservices/
[^12]:JAVA实现跨平台 https://www.cnblogs.com/lujiahua/p/11404611.html
[^13]:鸿蒙OS实现跨平台 https://blog.csdn.net/csdnsevenn/article/details/99364263
[^14]:跨平台 https://baike.baidu.com/item/%E8%B7%A8%E5%B9%B3%E5%8F%B0/8558902?fr=aladdin https://baike.baidu.com/item/跨平台/8558902?fr=aladdin
[^15]:Linux系统移植 https://blog.csdn.net/weixin_40654382/article/details/88326589
[^16]:概念篇---Microkernel(微内核) https://blog.csdn.net/drsonxu/article/details/80922826
[^17]:Socket通信原理 https://www.cnblogs.com/wangcq/p/3520400.html
[^18]:进程间通信（IPC）-mmap基本概念 https://www.pianshen.com/article/31741013838/
[^19]:《从零开始学架构》十：微服务和微内核架构 https://blog.csdn.net/qq_41594698/article/details/102698165
[^20]:基于注册表的微内核模型管理服务系统的设计与实现 https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFD2001&filename=SJSJ200103013&v=HtJh1yePPJV39UznW1Y6BCptjCocqAZWr12cl66EAyLdZbR7MYJ30NQbv5GgyxSG
[^21]:微内核与宏内核 https://upload-images.jianshu.io/upload_images/4324074-82eb29cce869b546.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp
[^22]: Rust官网 https://www.rust-lang.org/
[^23]:Rust语言百度百科 https://baike.baidu.com/item/Rust%E8%AF%AD%E8%A8%80/9502634?fr=aladdin
[^24]:浅谈几种跨平台方案 https://zhuanlan.zhihu.com/p/148820818
[^25]:微内核(microkernel)相关 https://blog.csdn.net/chiminmang7244/article/details/100933464

[^26]: 基于栈的虚拟机 VS 基于寄存器的虚拟机 https://blog.csdn.net/dashuniuniu/article/details/50347149
[^27]: 基于栈虚拟机和基于寄存器虚拟机的比较 https://blog.csdn.net/u012481172/article/details/50904574
[^28]: 虚拟机（基于栈还是基于寄存器）之谈 https://blog.csdn.net/lxlmycsdnfree/article/details/78638124
[^29]: Virtual Machine Showdown: Stack Versus Registers http://www.usenix.org/events/vee05/full_papers/p153-yunhe.pdf



​																																									2021年4月11日